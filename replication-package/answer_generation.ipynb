{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d97440",
   "metadata": {},
   "source": [
    "# RAG Answer Generation\n",
    "\n",
    "To run this notebook successfully, you need to configure three main components:\n",
    "\n",
    "### 1. Dataset Selection\n",
    "\n",
    "- **Location**: Update the `dataset_folder`\n",
    "- **Files**: Ensure your dataset contains a `questions.json` file with the question data\n",
    "- **Sample Size**: Modify `NUM_SAMPLES` to control how many questions to process\n",
    "\n",
    "### 2. RAGnaroX System Execution\n",
    "\n",
    "- **Endpoint Configuration**: Set the RAG system endpoint in your `.env` file:\n",
    "  ```\n",
    "  RAG_API_URL=http://127.0.0.1:10000/v1/chat/completions\n",
    "  RAG_API_METHOD=GET\n",
    "  ```\n",
    "- **System Requirements**: Ensure RAGnaroX is running and accessible at the specified endpoint\n",
    "- **API Format**: The system expects REST API calls with JSON payloads containing user questions\n",
    "\n",
    "### 3. SSH Connection for System Logging\n",
    "\n",
    "- **Remote Server**: Configure SSH credentials in `.env` file:\n",
    "  ```\n",
    "  SSH_PASSWORD=your_ssh_password\n",
    "  ```\n",
    "- **Server Details**: Update `ssh_user_host` and `remote_dir` variables in cell 4\n",
    "- **Logging Script**: Ensure `log_system.sh` exists on the remote server for performance monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff307ebc79d0b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T09:25:39.949195Z",
     "start_time": "2025-09-28T09:25:39.944372Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set your dataset folder here (e.g. 'single-hop-RAG-dataset', 'multi-hop-RAG-dataset', 'lang-RAG-dataset')\n",
    "dataset_folder = 'datasets/single-hop-RAG-dataset/'  # Change as needed\n",
    "input_json = ('questions.json')  # Change as needed\n",
    "output_json = ('5-doc_single_qwen4B.json')\n",
    "log_filename = output_json.replace('.json', '_log.csv')\n",
    "input_json_path = os.path.join(dataset_folder, input_json)\n",
    "output_json_path = os.path.join(dataset_folder, output_json)\n",
    "answer_file_path = os.path.abspath('agent_files/answer.json')\n",
    "answer_archive_path = os.path.join(dataset_folder, 'answer_generated_all.json')\n",
    "logging_path = os.path.join(dataset_folder, 'logging.json')\n",
    "\n",
    "NUM_SAMPLES = 1000  # Change as needed\n",
    "RAG_API_URL = os.environ.get(\n",
    "    'RAG_API_URL', 'http://127.0.0.1:10000/v1/chat/completions')\n",
    "RAG_API_METHOD = os.environ.get('RAG_API_METHOD', 'GET').upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4ccb5b9f491da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T09:25:39.958045Z",
     "start_time": "2025-09-28T09:25:39.953568Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_rest_api(question):\n",
    "\n",
    "    # Archive and remove any existing local agent answer file\n",
    "    if os.path.exists(answer_file_path):\n",
    "        with open(answer_file_path, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "        with open(answer_archive_path, 'a', encoding='utf-8') as f:\n",
    "            json.dump(existing_data, f, indent=2, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "        os.remove(answer_file_path)\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    payload = {'messages': [{'role': 'user', 'content': question}]}\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = requests.request(\n",
    "            method=RAG_API_METHOD,\n",
    "            url=RAG_API_URL,\n",
    "            headers=headers,\n",
    "            data=json.dumps(payload),\n",
    "            timeout=60\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "    except Exception as e:\n",
    "        print(f'Request failed: {e}')\n",
    "        return {'response': '', 'retrieved_contexts': [], 'response_time': None}\n",
    "    end_time = time.time()\n",
    "    response_time = end_time - start_time\n",
    "    try:\n",
    "        with open(logging_path, 'a', encoding='utf-8') as log_file:\n",
    "            json.dump(response_json, log_file, indent=2, ensure_ascii=False)\n",
    "            log_file.write('\\n')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Updated parsing for nested 'Result' key\n",
    "    message = response_json.get('content', {}).get('Result', {})\n",
    "    answer = message.get('content', '') if isinstance(message, dict) else ''\n",
    "    rag_entries = message.get(\n",
    "        'rag_entries', []) if isinstance(message, dict) else []\n",
    "    retrieved_contexts = [entry.get('text', '')\n",
    "                          for entry in rag_entries if isinstance(entry, dict)]\n",
    "    print(f'Retrieved {len(retrieved_contexts)} chunks for question\\n')\n",
    "    return {'response': answer, 'retrieved_contexts': retrieved_contexts, 'response_time': response_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6322b3e664c098b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T09:25:39.967879Z",
     "start_time": "2025-09-28T09:25:39.961931Z"
    }
   },
   "outputs": [],
   "source": [
    "def delete_remote_csv_files(ssh_user_host, ssh_password, remote_dir):\n",
    "    \"\"\"Delete all .csv files in the remote directory via SSH before generating new logs.\"\"\"\n",
    "    import subprocess\n",
    "    remote_delete_cmd = f\"find {remote_dir} -maxdepth 1 -name '*.csv' -delete\"\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"sshpass\", \"-p\", ssh_password,\n",
    "            \"ssh\", ssh_user_host, remote_delete_cmd\n",
    "        ], check=True)\n",
    "        print(f\"Deleted all .csv files in remote directory: {remote_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete remote .csv files: {e}\")\n",
    "\n",
    "\n",
    "def start_remote_logging(ssh_user_host, ssh_password, remote_dir, log_filename):\n",
    "    \"\"\"Start remote system logging script via SSH.\"\"\"\n",
    "    import subprocess\n",
    "    remote_cmd = f'export LC_ALL=C LANG=C; cd {remote_dir} && bash log_system.sh -o {log_filename}'\n",
    "    try:\n",
    "        proc = subprocess.Popen([\n",
    "            \"sshpass\", \"-p\", ssh_password,\n",
    "            \"ssh\", ssh_user_host, remote_cmd\n",
    "        ])\n",
    "        print('Started remote logging.')\n",
    "        return proc\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to start remote logging: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def stop_remote_logging(ssh_user_host, ssh_password, log_filename):\n",
    "    \"\"\"Stop remote system logging script via SSH.\"\"\"\n",
    "    import subprocess\n",
    "    stop_cmd = f\"pkill -f 'bash log_system.sh -o {log_filename}'\"\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"sshpass\", \"-p\", ssh_password,\n",
    "            \"ssh\", ssh_user_host, stop_cmd\n",
    "        ], check=True)\n",
    "        print('System logging stopped.')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to stop remote logging: {e}\")\n",
    "\n",
    "\n",
    "def copy_remote_log_to_local(ssh_user_host, ssh_password, remote_dir, log_filename):\n",
    "    \"\"\"Copy the generated CSV log file from remote to local results folder.\"\"\"\n",
    "    import subprocess\n",
    "    import os\n",
    "    local_log_path = os.path.join('results_final', log_filename)\n",
    "    remote_log_path = os.path.join(remote_dir, log_filename)\n",
    "    scp_cmd = [\n",
    "        \"sshpass\", \"-p\", ssh_password,\n",
    "        \"scp\", f\"{ssh_user_host}:{remote_log_path}\", local_log_path\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(scp_cmd, check=True)\n",
    "        print(f\"Copied remote log file to {local_log_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to copy remote log file: {e}\")\n",
    "\n",
    "\n",
    "def update_answers_via_rest(input_path, output_path, num_examples=NUM_SAMPLES):\n",
    "    \"\"\"Generate answers via REST API and handle remote logging.\"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    ssh_user_host = \"host_URL\"\n",
    "    ssh_password = os.environ.get(\n",
    "        \"SSH_PASSWORD\", \"your_password\")  # Now loads from .env\n",
    "    remote_dir = \"/workspace/rag_systems_perforamnce_logs/rag_evaluation/\"\n",
    "\n",
    "    # Step 1: Clean up remote logs\n",
    "    delete_remote_csv_files(ssh_user_host, ssh_password, remote_dir)\n",
    "\n",
    "    # Step 2: Start remote logging\n",
    "    log_proc = start_remote_logging(\n",
    "        ssh_user_host, ssh_password, remote_dir, log_filename)\n",
    "\n",
    "    # Step 3: Generate answers\n",
    "    try:\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        updated_data = []\n",
    "        for i, entry in enumerate(data[:num_examples]):\n",
    "            question = entry.get('user_input', '')\n",
    "            print(f'ðŸ”„ Generating answer for entry {i + 1}/{num_examples}')\n",
    "            generated = call_rest_api(question)\n",
    "            updated_entry = entry.copy()\n",
    "            updated_entry['response'] = generated.get('response', '')\n",
    "            updated_entry['retrieved_contexts'] = generated.get(\n",
    "                'retrieved_contexts', [])\n",
    "            updated_entry['response_time'] = generated.get(\n",
    "                'response_time', None)\n",
    "            updated_data.append(updated_entry)\n",
    "        # Save results\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        results_path = os.path.join(\n",
    "            'results_final', os.path.basename(output_path))\n",
    "        with open(results_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(updated_data, f, indent=2, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        print(f'Error during answer generation: 100{e}')\n",
    "\n",
    "    # Step 4: Stop remote logging and copy log file\n",
    "    stop_remote_logging(ssh_user_host, ssh_password, log_filename)\n",
    "    copy_remote_log_to_local(\n",
    "        ssh_user_host, ssh_password, remote_dir, log_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860663740e39087b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T15:50:40.091569Z",
     "start_time": "2025-09-28T09:25:39.972724Z"
    }
   },
   "outputs": [],
   "source": [
    "# save logs and generated answers to results_final folder\n",
    "os.makedirs('results_final', exist_ok=True)\n",
    "update_answers_via_rest(input_json_path, output_json_path, NUM_SAMPLES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
