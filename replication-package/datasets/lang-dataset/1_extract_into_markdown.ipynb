{
 "cells": [
  {
   "cell_type": "code",
   "id": "d21d1738595547ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T06:14:11.371202Z",
     "start_time": "2025-09-03T06:14:11.179096Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "notebook_dir = Path(os.path.abspath('')).resolve()\n",
    "os.chdir(notebook_dir)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "languages = ['en', 'de', 'es']\n",
    "# If you want to add Swedish, add 'se' to the list above\n",
    "# languages = ['en', 'de', 'es', 'se']\n",
    "\n",
    "# All cross-language pairs\n",
    "language_pairs = list(itertools.permutations(languages, 2))\n",
    "# Add same-language pairs\n",
    "language_pairs += [('en', 'en'), ('de', 'de'), ('es', 'es')]\n",
    "# To add 'se-se', uncomment the next line if you have Swedish data:\n",
    "# language_pairs.append(('se', 'se'))\n",
    "\n",
    "print(\"Processing the following language pairs:\")\n",
    "for context_lang, question_lang in language_pairs:\n",
    "    print(f\"- Context: {context_lang}, Questions: {question_lang}\")\n",
    "\n",
    "base_dir = Path('dataset/MLQA_V1/dev')\n",
    "questions_base = Path('questions')  # All JSONs go here\n",
    "corpus_base = Path('corpus')        # Context markdowns go here\n",
    "\n",
    "print(f\"Looking for files in: {base_dir.absolute()}\")\n",
    "print(f\"Base directory exists: {base_dir.exists()}\")\n",
    "\n",
    "for context_lang, question_lang in language_pairs:\n",
    "    context_file = f'dev-context-{context_lang}-question-{question_lang}.json'\n",
    "    json_path = base_dir / context_file\n",
    "\n",
    "    print(\n",
    "        f\"\\nProcessing {context_lang} contexts with {question_lang} questions\")\n",
    "    print(f\"Reading from: {context_file}\")\n",
    "\n",
    "    if not json_path.exists():\n",
    "        print(f'File not found: {json_path}')\n",
    "        continue\n",
    "\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    qa_pairs = []\n",
    "\n",
    "    for entry in data.get('data', []):\n",
    "        for para in entry.get('paragraphs', []):\n",
    "            for qa in para.get('qas', []):\n",
    "                question = qa.get('question', '').replace('\\n', ' ').strip()\n",
    "                answers = qa.get('answers', [])\n",
    "                if answers and len(answers) > 0:\n",
    "                    answer_text = answers[0].get('text', '').strip()\n",
    "                    if question and answer_text:\n",
    "                        qa_pairs.append({\n",
    "                            'user_input': question,\n",
    "                            'reference': answer_text,\n",
    "                            'response': \"\",\n",
    "                            'retrieved_contexts': \"\"\n",
    "                        })\n",
    "\n",
    "    # Write QA pairs for this language pair to the shared Questions folder\n",
    "    questions_base.mkdir(parents=True, exist_ok=True)\n",
    "    qa_file = questions_base / f'qa_pairs_{context_lang}-{question_lang}.json'\n",
    "    with open(qa_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(qa_pairs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f'Extracted for {context_lang}-{question_lang}:')\n",
    "    print(f'- {len(qa_pairs)} question-answer pairs saved to {qa_file}')\n",
    "\n",
    "    # Write contexts - one file per title in the corpus/{pair} folder (no contexts subfolder)\n",
    "    corpus_pair_dir = corpus_base / f\"{context_lang}-{question_lang}\"\n",
    "    corpus_pair_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Group contexts by title\n",
    "    contexts_by_title = {}\n",
    "    for entry in data.get('data', []):\n",
    "        title = entry.get('title', 'Untitled').replace('\\n', ' ').strip()\n",
    "        for para in entry.get('paragraphs', []):\n",
    "            context = para.get('context', '').replace('\\n', ' ').strip()\n",
    "            if context:\n",
    "                if title not in contexts_by_title:\n",
    "                    contexts_by_title[title] = []\n",
    "                contexts_by_title[title].append(context)\n",
    "\n",
    "    for title, contexts in contexts_by_title.items():\n",
    "        # Create a safe filename from the title\n",
    "        safe_title = \"\".join(c for c in title if c.isalnum()\n",
    "                             or c in (' ', '-', '_')).rstrip()\n",
    "        safe_title = safe_title.replace(' ', '_')\n",
    "        context_file = corpus_pair_dir / f'{safe_title}.md'\n",
    "        with open(context_file, 'w', encoding='utf-8') as f:\n",
    "            # Concatenate all context paragraphs into a single string, separated by spaces\n",
    "            all_text = \" \".join(contexts).replace('\\n', ' ').strip()\n",
    "            f.write(f'{title}: {all_text}\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/bdornauer/git-projects/rag-evaluation/lang-RAG-dataset\n",
      "Processing the following language pairs:\n",
      "- Context: en, Questions: de\n",
      "- Context: en, Questions: es\n",
      "- Context: de, Questions: en\n",
      "- Context: de, Questions: es\n",
      "- Context: es, Questions: en\n",
      "- Context: es, Questions: de\n",
      "- Context: en, Questions: en\n",
      "- Context: de, Questions: de\n",
      "- Context: es, Questions: es\n",
      "Looking for files in: /Users/bdornauer/git-projects/rag-evaluation/lang-RAG-dataset/dataset/MLQA_V1/dev\n",
      "Base directory exists: True\n",
      "\n",
      "Processing en contexts with de questions\n",
      "Reading from: dev-context-en-question-de.json\n",
      "Extracted for en-de:\n",
      "- 512 question-answer pairs saved to questions/qa_pairs_en-de.json\n",
      "\n",
      "Processing en contexts with es questions\n",
      "Reading from: dev-context-en-question-es.json\n",
      "Extracted for en-es:\n",
      "- 500 question-answer pairs saved to questions/qa_pairs_en-es.json\n",
      "\n",
      "Processing de contexts with en questions\n",
      "Reading from: dev-context-de-question-en.json\n",
      "Extracted for de-en:\n",
      "- 512 question-answer pairs saved to questions/qa_pairs_de-en.json\n",
      "\n",
      "Processing de contexts with es questions\n",
      "Reading from: dev-context-de-question-es.json\n",
      "Extracted for de-es:\n",
      "- 196 question-answer pairs saved to questions/qa_pairs_de-es.json\n",
      "\n",
      "Processing es contexts with en questions\n",
      "Reading from: dev-context-es-question-en.json\n",
      "Extracted for es-en:\n",
      "- 500 question-answer pairs saved to questions/qa_pairs_es-en.json\n",
      "\n",
      "Processing es contexts with de questions\n",
      "Reading from: dev-context-es-question-de.json\n",
      "Extracted for es-de:\n",
      "- 196 question-answer pairs saved to questions/qa_pairs_es-de.json\n",
      "\n",
      "Processing en contexts with en questions\n",
      "Reading from: dev-context-en-question-en.json\n",
      "Extracted for en-en:\n",
      "- 1148 question-answer pairs saved to questions/qa_pairs_en-en.json\n",
      "\n",
      "Processing de contexts with de questions\n",
      "Reading from: dev-context-de-question-de.json\n",
      "Extracted for de-de:\n",
      "- 512 question-answer pairs saved to questions/qa_pairs_de-de.json\n",
      "\n",
      "Processing es contexts with es questions\n",
      "Reading from: dev-context-es-question-es.json\n",
      "Extracted for es-es:\n",
      "- 500 question-answer pairs saved to questions/qa_pairs_es-es.json\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
